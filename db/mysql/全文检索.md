# 创建全文索引

## 创建table时，创建全文索引
```
CREATE TABLE test_items (
  FTS_DOC_ID BIGINT UNSIGNED AUTO_INCREMENT NOT NULL PRIMARY KEY,
  body TEXT,
  FULLTEXT KEY `ngram_idx` (`body`) /*!50100 WITH PARSER `ngram` */ 
) ENGINE=InnoDB CHARACTER SET utf8mb4;
 
INSERT INTO test_items (body) VALUES
  ('東京都で遊ぶ'),
  ('京都で遊ぶ'),
  ('大阪で遊ぶ'),
  ('京都と大阪で遊ぶ');
```

## alter table 创建全文索引

<font style='color:red'>注意一定要用WITH PARSER ngram</font>
```
ALTER TABLE test_items ADD FULLTEXT INDEX ngram_idx (body) WITH PARSER ngram;
```

## 全文检索查询

```
SELECT * FROM test_items WHERE MATCH (body) AGAINST ('京都' IN BOOLEAN MODE);

# FTS_DOC_ID, body
'1', '東京都で遊ぶ'
'2', '京都で遊ぶ'
'4', '京都と大阪で遊ぶ'

SELECT * FROM test_items WHERE MATCH (body) AGAINST ('京都' IN NATURAL LANGUAGE MODE );

# FTS_DOC_ID, body
'1', '東京都で遊ぶ'
'2', '京都で遊ぶ'
'4', '京都と大阪で遊ぶ'

```

## 得到匹配的权重比率

```
SELECT fts_doc_id, MATCH (body) AGAINST ('京都' IN BOOLEAN MODE)
 AS score FROM test_items;
```


## 检索方式
主要有以下两种

### IN NATURAL LANGUAGE MODE 自然语言检索

自然语言模式是 MySQL 默认的全文检索模式。
自然语言模式不能使用操作符，不能指定关键词必须出现或者必须不能出现等复杂查询。
自然语言搜索引擎将计算每一个文档对象和查询的相关度。这里，相关度是基于匹配的关键词的个数，以及关键词在文档中出现的次数。在整个索引中出现次数越少的词语，匹配时的相关度就越高。相反，非常常见的单词将不会被搜索，如果一个词语的在超过 50% 的记录中都出现了，那么自然语言的搜索将不会搜索这类词语。上面提到的，测试表中必须有 4 条以上的记录，就是这个原因。

这个机制也比较好理解，比如说，一个数据表存储的是一篇篇的文章，文章中的常见词、语气词等等，出现的肯定比较多，搜索这些词语就没什么意义了，需要搜索的是那些文章中有特殊意义的词，这样才能把文章区分开。

因为50% 的限制，如果查询不出来，可以使用布尔全文索引查询来解决，使用下面的命令，a、aa、aaa、aaaa 就都被查询出来了。

```
select * test where match(content) against('a*' in boolean mode);
```


### IN BOOLEAN MODE 布尔检索

BOOLEAN 模式可以使用操作符，可以支持指定关键词必须出现或者必须不能出现或者关键词的权重高还是低等复杂查询。以下是布尔检索的特色

- 不剔除50%以上符合的row。 
- 不自动以相关性反向排序。 
- 可以对没有FULLTEXT index的字段进行搜寻，但会非常慢。 
- 限制最长与最短的字符串。 
- 套用Stopwords。

在布尔搜索中，我们可以在查询中自定义某个被搜索的词语的相关性，当编写一个布尔搜索查询时，可以通过一些前缀修饰符来定制搜索。

MySQL 内置的修饰符，上面查询最小搜索长度时，搜索结果 ft_boolean_syntax 变量的值就是内置的修饰符，下面简单解释几个，更多修饰符的作用可以查手册

- + 必须包含该词
- - 必须不包含该词
- > 提高该词的相关性，查询的结果靠前
- < 降低该词的相关性，查询的结果靠后
- (*)星号 通配符，只能接在词后面
- ~   将其相关性由正转负，表示拥有该字会降低相关性(但不像 - 将之排除)，只是排在较后面权重值降低。 
- " " 用双引号将一段句子包起来表示要完全相符，不可拆字。



# 详述 
全文检索是利用文字索引来检索数据，建立索引是需要分词，所以全文检索会比like的检索速度快，但是精度会低一些，因为分词的合理性也有可能会检索出不需要的数据。

## parser

mysql 默认用的parser是针对于英文系的以空格来区分单词的parser，不适用于中，日，韩语言。

从 MySQL 5.7.6 开始，MySQL内置了ngram全文解析器，在InnoDB数据库引擎中用来支持中文、日文、韩文分词。
MySQL 5.7.6以前只支持 myIsam数据库引擎的英文全文检索

<font style='color:red'>注意：创建full text index时要指定 ngram，不然会检索不出数据来</font>

## ngram分词
例如，用ngram全文解析器对“恭喜发财”进行分词:

```
n=1: '恭', '喜', '发', '财' 
n=2: '恭喜', '喜发', '发财' 
n=3: '恭喜发', '喜发财' 
n=4: '恭喜发财'
```

## 全文检索全局变量

### MyISAM engine 英语系 parser 使用的分词变量

```sh
# 就是分词的最小单位，4就是最小以4个单词来分词索引，小于4个单词就不会被查询出来
ft_min_word_len = 4; 
ft_max_word_len = 84;
```

### InnoDB engine 英语系 parser 使用的分词变量
innodb_ft_min_token_size 默认为3
```sh
show variables like '%token_size';
innodb_ft_min_token_size = 3;
innodb_ft_max_token_size = 84;
```

### InnoDB engine  ngram parser 使用的分词变量
```sh
show variables like 'ngram_token_size'
# Variable_name, Value
'ngram_token_size', '2'
```
默认分词大小为2。

当使用ngram parser分词时，参照此变量
要记住，分词的SIZE越大，索引的体积就越大，所以要根据自身情况来设置合适的大小

例如，用ngram全文解析器对“恭喜发财”进行分词:

因为'ngram_token_size' 为 '2'

所以索引如下
```
'恭喜', '喜发', '发财' 
```
<font style='color:red'>
这里一定要注意ngram_token_size的大小，如果设置为2时，
当你检索一个字时，是不会检索出任何数据的。
</font>

### 显示ft变量
show variables like '%ft_%';
```
# Variable_name, Value
'ft_boolean_syntax', '+ -><()~*:\"\"&|'
'ft_max_word_len', '84'
'ft_min_word_len', '4'
'ft_query_expansion_limit', '20'
'ft_stopword_file', '(built-in)'
'innodb_ft_aux_table', ''
'innodb_ft_cache_size', '8000000'
'innodb_ft_enable_diag_print', 'OFF'
'innodb_ft_enable_stopword', 'ON'
'innodb_ft_max_token_size', '84'
'innodb_ft_min_token_size', '3'
'innodb_ft_num_word_optimize', '2000'
'innodb_ft_result_cache_limit', '2000000000'
'innodb_ft_server_stopword_table', ''
'innodb_ft_sort_pll_degree', '2'
'innodb_ft_total_cache_size', '640000000'
'innodb_ft_user_stopword_table', ''
```



### 设置变量
修改MySQL配置文件 my.ini 

```
# 全文检索分词数
[mysqld]
ngram_token_size=2
```
需要重启 MySQL 服务器，并修复全文索引。注意，修改完参数以后，一定要修复下索引，不然参数不会生效。或者删除索引后重新创建。

### 修复索引
```
repair table test_items quick;
```



## InnoDB 全文インデックスの最適化
```
set GLOBAL innodb_optimize_fulltext_only=ON;
OPTIMIZE TABLE test_items;
```

## 注意

- 只能在类型为CHAR、VARCHAR或者TEXT的字段上创建全文索引。
- 全文索引只支持InnoDB和MyISAM引擎。
- MATCH (columnName) AGAINST ('keywords')。MATCH()函数使用的字段名，必须要与创建全文索引时指定的字段名一致。如上面的示例，MATCH (title,body)使用的字段名与全文索引ft_articles(title,body)定义的字段名一致。如果要对title或者body字段分别进行查询，就需要在title和body字段上分别创建新的全文索引。
- MATCH()函数使用的字段名只能是同一个表的字段，因为全文索引不能够跨多个表进行检索。
- 如果要导入大数据集，使用先导入数据再在表上创建全文索引的方式要比先在表上创建全文索引再导入数据的方式快很多，所以全文索引是很影响TPS的。


##  形態素解析
是根据字典来进行分词，索引，现在mysql不支持字典解析，ElasticSearch， solor 支持。

辞書をつかって意味のある単語にわけ、それを半角スペースでくっつけたもの。
この辞書はMeCabとかが有名。

N-gramと違い、単語の文字数がバラバラになるので、ft_min_word_len、innodb_ft_min_token_sizeには1を指定してあげた方が良さげかしら？
データ投入時、辞書にかけて単語を分け、それを投入してあげる。
また、検索時にも辞書にかけて単語に分けてやった方がいいたぶん。